<!-- zhang -->

<p style="text-indent:0;"><span class="first-letter"> Our </span> environments are getting smarter. Advances in sensors, actuators, and communication have made the vision of ambient intelligence increasingly achievable. We have seen an increasing number of smarts around us such as voice assistants, service robots, UAVs, autonomous vehicles, and a broader array of connective objects in IoT. Professor Yang Zhang creates enabling technologies to make ambient intelligence more powerful in facilitating the future of work, healthcare, and education. He also researches human-centered design frameworks to make ambient intelligence and the environments they reside in equally accessible to all and can be developed by anyone. Professor Zhang is currently directing the Human-Centered Computing & Intelligent Sensing Lab (HiLab) at UCLA ECE. <span>https://www.hilab.dev</span></p>

<h3>Pillar 1: Create more powerful ambient intelligence</h3>
<p>HiLab creates sensing technologies to extend the capabilities of ambient intelligence. Such technologies improve the communication bandwidth between ambient intelligence by prepping everyday objects for interactivity -- intelligent walls that sense human poses, cameras that turn surfaces into high-precision touchscreens. Additionally, HiLab develops novel sensors that monitor events and user activities for environmental and personal informatics, such as cameras that sense vibrations to recognize building- and city-scale activities. Overall, this research pillar enables ambient intelligence to acquire knowledge from people either explicitly (i.e., interaction) or implicitly (i.e., event and activity recognition) in a practical manner.</p>

<h3>Pillar 2: Use ambient intelligence to make the physical world accessible to all</h3>
<p>Ambient intelligence also opens new opportunities for making the physical world equally accessible to all. Specifically, HiLab develops systems that can digitize the physical world for accessibility applications, including virtual and augmented reality techniques that allow people with disabilities to better navigate through a world full of barriers and inaccessible information. HiLab also creates intelligent sensing and actuation systems that can be easily deployed by people with motor impairments (e.g., users of wheelchairs) for independent living and improved life qualities.</p>

<h3>Pillar 3: Lower the barrier for everyone to create ambient intelligence</h3>
<p>Finally, HiLab aims to empower everyone to create ambient intelligence. By improving their environments, people improve their lives (e.g., switching for a brighter lightbulb). We believe that people should be able to create ambient intelligence as easily as switching a lightbulb. Besides sponsoring the community with toolkits of existing research, HiLab also seeks general design frameworks that can be easily adopted by anyone for any application. Ongoing research in this pillar includes 1) creating open-source sensor toolkits, 2) developing frameworks for developers to create human-centered energy-constrained systems, and 3) using augmented and virtual reality to facilitate developing and debugging of smart environments.</p>




<p style="text-indent:0;"><span class="first-letter"> My </span>  research interests cover a wide range, mainly in the intersections of control theory, geometry, network sciences, machine learning, and game theory. For the purpose of this brief note, I focus on one recent topic that has occupied some of my time.</p>

<p>The abundance of access to data and advanced sensing apparatus has made the interplay between ``uncertainty'', “stability", and “performance” at the cusp of focus for achieving certifiable autonomy. Providing such certificates is in the roots of control theory, with the foundations of robustness and adaptation going back decades. Adaptive control, for instance, was built precisely to deal with unknown parameters while providing some stability certificates. Much of the classical development of the subject, however, was focused on systems with models at hand. The key challenge in nowadays complex problems such as autonomous driving is lack of such models, along with the fact that the decisions are made in an online fashion. The latter is in sharp contrast with offline problems in machine learning, such as algorithms behind Alpha Go, where training algorithms provide incomparable results. On the other hand, model-free techniques, such as reinforcement learning, often do not come with stability guarantees. The expected standards for future autonomous vehicles are in a way that robustness and stability guarantees are indispensable.</p>

<p>As control theorists, we are often concerned with stability; we do not want systems to go unstable, ever. In this sense, we are trained to be conservative. Learning about unknowns, by its nature, requires exploration, and enforcing stability prevents exploratory decisions. If the objective is for an autonomous vehicle to follow a certain path, with the abundance of unknowns present, implementing classical control strategies with robustness certificates would simply bring the car to halt. In this sense, if the measure of performance is how well the path is followed, the performance will be very poor. On the contrary, core techniques in machine learning, ranging from online optimization to reinforcement learning, are often solely concerned with performance. Even though it is a gross generalization, the interplay I depicted is present across the board. The key question that I am interested in is on how to mathematically capture this interplay, and how to generate certificates that meet the standards of future autonomous systems.</p>